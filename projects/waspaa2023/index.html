
<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8">
    <title>WASPAA 2023: Lead Sheet Alignment</title>
    <style>
      body {
        font-family: Arial, sans-serif;
        text-align: center;
        margin: 20px;
      }
      .abstract{
      margin: 20px auto 40px auto;
      text-align: justify;
      width: 50%;
      }
      .authors.links{
        font-size: 14px;
        margin: 20px auto 40px auto;
        text-align: center;
        width: 50%;
      }
    </style>
  </head>
  <body>

  <h1>Annotating Jazz Recordings Using Lead Sheet Alignment with Deep Chroma Features</h1>

  <!-- Authors Section -->
  <div class="authors">
    <p>
      <b>Ivan Shanin, Simon Dixon</b>
      <br>
      <i>Centre for Digital Music, Queen Mary University of London</i>
    </p>
  </div>
    <!-- Authors Section -->
    <div class="links">
      <p>
        [ <a href="https://ieeexplore.ieee.org/abstract/document/10248107">paper</a> | <a href="404">github (coming soon)</a> | <a href="https://youtu.be/-xL88_XYWwc">video</a> | <a href="https://drive.google.com/file/d/1a0UNSeZiT4etUPRiI4IIKdgvzH4Nv_Ef/view?usp=share_link">slides</a> ]
      </p>
    </div>
  <!-- Abstract Section -->
  <div class="abstract">
    <p>
      The automatic recognition of chords from jazz recordings remains largely an unsolved challenge, due to the broad harmonic vocabulary, the freedom of interpretation in performance, the rich variety of expressive techniques, and the limited availability of accurately labeled training data. In practice, many jazz recordings contain performances of popular compositions that are known as standards. We propose an approach that takes into consideration available prior information about chord changes of popular compositions known as lead sheets. Instead of estimating the exact chord symbol at each time point, we aim to identify the position in the lead sheet, thereby solving the audio-to-score alignment task (with a distinction that the score does not contain any melodic information, and the harmonic annotation is only approximate). This approach also solves the structural segmentation problem, as segment boundaries are available in the lead sheets. To achieve this goal we combine a multi-task convolutional recurrent neural architecture with an alignment algorithm based on a Hidden Markov Model. The proposed approach uses the iRealPro corpus of 1186 lead sheets and is evaluated on a test set of the 220 audio excerpts in the Weimar Jazz Database, showing that it outperforms previously published work.
    </p>
  </div>



  <!-- First YouTube Video -->
  <div>
    
<iframe width="560" height="315" src="https://www.youtube.com/embed/Tinh1ZDTa1k" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
  </div>

  <!-- Second YouTube Video -->
  <div>
    

    <iframe width="560" height="315" src="https://www.youtube.com/embed/A2kHN2JW2UM" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
  </div>

    <!--  YouTube Video -->
    <div>
    

      <iframe width="560" height="315" src="https://www.youtube.com/embed/xw7gkVLUAdo" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
    </div>

    <div>
    

      <iframe width="560" height="315" src="https://www.youtube.com/embed/7_bAKOCTBwc" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
    </div>


</body>
</html>